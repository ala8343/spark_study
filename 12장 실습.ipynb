{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-17-134.ec2.internal:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[11] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame, DataSet으로 RDD 생성하기\n",
    "spark.range(10).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[18] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#row 객체에서 값을 추출\n",
    "spark.range(10).toDF(\"id\").rdd.map(lambda row: row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD 사용하여 DataFrame이나 Dataset 생성\n",
    "spark.range(10).rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로컬럴렉션으로 RDD 생성하기\n",
    "myCollection = \"Spark The Definitive Guide : Big Data Processing Made Simple\"\\\n",
    "  .split(\" \")\n",
    "words = spark.sparkContext.parallelize(myCollection, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myWords'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD에 이름 지정\n",
    "words.setName(\"myWords\")\n",
    "words.name() # myWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터소스로 RDD 생성\n",
    "#spark.sparkContext.textFile(\"/some/path/withTextFiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distinct -> RDD에서 중복된 데이터 제고\n",
    "#words.distinct.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Simple']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter\n",
    "def startsWithS(individual):\n",
    "  return individual.startswith(\"S\") #S로 시작하는 단어만 남도록 필터링\n",
    "\n",
    "words.filter(lambda word: startsWithS(word)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 'S', True),\n",
       " ('The', 'T', False),\n",
       " ('Definitive', 'D', False),\n",
       " ('Guide', 'G', False),\n",
       " (':', ':', False),\n",
       " ('Big', 'B', False),\n",
       " ('Data', 'D', False),\n",
       " ('Processing', 'P', False),\n",
       " ('Made', 'M', False),\n",
       " ('Simple', 'S', True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map\n",
    "#주어진 입력을 원하는 값으로 반환하는 함수 명시하고 레코드별로 적용\n",
    "words2 = words.map(lambda word: (word, word[0], word.startswith(\"S\")))\n",
    "words2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 'S', True), ('Simple', 'S', True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2.filter(lambda record: record[2]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'p', 'a', 'r', 'k']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatmap\n",
    "#단어를 문자 집합으로 변환\n",
    "words.flatMap(lambda word: list(word)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Definitive', 'Processing']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sortBy\n",
    "words.sortBy(lambda word: len(word) * -1).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomSplit\n",
    "fiftyFiftySplit = words.randomSplit([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#액션\n",
    "#reduce\n",
    "#모든 값을 하나의 값으로 만들기\n",
    "spark.sparkContext.parallelize(range(1, 21)).reduce(lambda x, y: x + y) # 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Processing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#가장 긴 단어를 찾는 예제\n",
    "def wordLengthReducer(leftWord, rightWord):\n",
    "  if len(leftWord) > len(rightWord):\n",
    "    return leftWord\n",
    "  else:\n",
    "    return rightWord\n",
    "\n",
    "words.reduce(wordLengthReducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count\n",
    "#전체 로우 수를 알 수 있다\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countApprox\n",
    "#count 함수의 근사치를 제한 시간 내에 계산\n",
    "confidence = 0.95\n",
    "timeoutMilliseconds = 400\n",
    "words.countApprox(timeoutMilliseconds, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countApproxDistinct\n",
    "words.countApproxDistinct(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words.countApproxDistinct(4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Spark': 1,\n",
       "             'The': 1,\n",
       "             'Definitive': 1,\n",
       "             'Guide': 1,\n",
       "             ':': 1,\n",
       "             'Big': 1,\n",
       "             'Data': 1,\n",
       "             'Processing': 1,\n",
       "             'Made': 1,\n",
       "             'Simple': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countByValue\n",
    "#RDD 값의 개수 구하기\n",
    "words.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countByValueApprox\n",
    "#words.countByValueApprox(1000, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spark'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first -> 데이터셋의 첫 번째 값 반환\n",
    "words.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max와 min\n",
    "#spark.sparkContext.parallelize(1 to 20).max()\n",
    "#spark.sparkContext.parallelize(1 to 20).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data', 'Definitive', 'Data', 'The', 'Definitive', 'Spark']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take\n",
    "#RDD에서 가져올 값으 개수를 파라미터로 사용\n",
    "words.take(5)\n",
    "words.takeOrdered(5)\n",
    "words.top(5)\n",
    "withReplacement = True\n",
    "numberToTake = 6\n",
    "randomSeed = 100\n",
    "words.takeSample(withReplacement, numberToTake, randomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 저장하기\n",
    "#saveAsTextFile\n",
    "#words.saveasTextFile(\"file:/tmp/bookTitle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시퀀스 파일\n",
    "#words.saveAsObjectFile(\"/tmp/my/sequenceFilePath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myWords ParallelCollectionRDD[30] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#캐싱\n",
    "words.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#저장소수준\n",
    "words.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#체크포인팅\n",
    "#RDD를 디스크에 저장하는 방식\n",
    "#spark.sparkContext.setCheckpointDir(\"/some/path/for/checkpointing\")\n",
    "#words.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '5']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD를 시스템 명령으로 전송하기\n",
    "#각 파티션을 wc 명령에 연결\n",
    "words.pipe(\"wc -l\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapPartitions\n",
    "words.mapPartitions(lambda part: [1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partition: 0 => Spark',\n",
       " 'partition: 0 => The',\n",
       " 'partition: 0 => Definitive',\n",
       " 'partition: 0 => Guide',\n",
       " 'partition: 0 => :',\n",
       " 'partition: 1 => Big',\n",
       " 'partition: 1 => Data',\n",
       " 'partition: 1 => Processing',\n",
       " 'partition: 1 => Made',\n",
       " 'partition: 1 => Simple']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def indexedFunc(partitionIndex, withinPartIterator):\n",
    "  return [\"partition: {} => {}\".format(partitionIndex,\n",
    "    x) for x in withinPartIterator]\n",
    "words.mapPartitionsWithIndex(indexedFunc).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello'], ['World']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.parallelize([\"Hello\", \"World\"], 2).glom().collect()\n",
    "# [['Hello'], ['World']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
