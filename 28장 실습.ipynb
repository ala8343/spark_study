{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-17-134.ec2.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: alpha for implicit preference (default: 1.0)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "coldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan)\n",
      "finalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\n",
      "implicitPrefs: whether to use implicit preference (default: False)\n",
      "intermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\n",
      "itemCol: column name for item ids. Ids must be within the integer value range. (default: item, current: movieId)\n",
      "maxIter: max number of iterations (>= 0). (default: 10, current: 5)\n",
      "nonnegative: whether to use nonnegative constraint for least squares (default: False)\n",
      "numItemBlocks: number of item blocks (default: 10)\n",
      "numUserBlocks: number of user blocks (default: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "rank: rank of the factorization (default: 10)\n",
      "ratingCol: column name for ratings (default: rating, current: rating)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1, current: 0.01)\n",
      "seed: random seed. (default: -1517157561977538513)\n",
      "userCol: column name for user ids. Ids must be within the integer value range. (default: user, current: userId)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "ratings = spark.read.text(\"file:///home/ubuntu/Spark-The-Definitive-Guide/data/sample_movielens_ratings.txt\")\\\n",
    "  .rdd.toDF()\\\n",
    "  .selectExpr(\"split(value , '::') as col\")\\\n",
    "  .selectExpr(\n",
    "    \"cast(col[0] as int) as userId\",\n",
    "    \"cast(col[1] as int) as movieId\",\n",
    "    \"cast(col[2] as float) as rating\",\n",
    "    \"cast(col[3] as long) as timestamp\")\n",
    "training, test = ratings.randomSplit([0.8, 0.2])\n",
    "als = ALS()\\\n",
    "  .setMaxIter(5)\\\n",
    "  .setRegParam(0.01)\\\n",
    "  .setUserCol(\"userId\")\\\n",
    "  .setItemCol(\"movieId\")\\\n",
    "  .setRatingCol(\"rating\")\n",
    "print(als.explainParams())\n",
    "alsModel = als.fit(training)\n",
    "predictions = alsModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|userId|            col|\n",
      "+------+---------------+\n",
      "|    28| [92, 5.123827]|\n",
      "|    28|[46, 4.8833604]|\n",
      "|    28| [12, 4.716059]|\n",
      "|    28|[81, 4.4394255]|\n",
      "|    28|[89, 4.1382756]|\n",
      "|    28|[82, 4.0096335]|\n",
      "|    28|[49, 3.8630824]|\n",
      "|    28|  [2, 3.733239]|\n",
      "|    28|[22, 3.6181092]|\n",
      "|    28|[38, 3.3592396]|\n",
      "|    26| [12, 7.031254]|\n",
      "|    26|[34, 6.9927745]|\n",
      "|    26|[87, 6.9834156]|\n",
      "|    26|[19, 6.5419154]|\n",
      "|    26| [32, 5.562295]|\n",
      "|    26| [7, 5.2005177]|\n",
      "|    26|[23, 5.0199385]|\n",
      "|    26|  [88, 5.00247]|\n",
      "|    26|[80, 4.9992037]|\n",
      "|    26| [92, 4.986472]|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+---------------+\n",
      "|movieId|            col|\n",
      "+-------+---------------+\n",
      "|     31|[17, 3.9742641]|\n",
      "|     31| [12, 3.776509]|\n",
      "|     31| [8, 3.0678513]|\n",
      "|     31| [9, 2.9888442]|\n",
      "|     31|[14, 2.8119066]|\n",
      "|     31| [23, 2.489113]|\n",
      "|     31|[21, 2.4762306]|\n",
      "|     31| [6, 2.2760584]|\n",
      "|     31| [2, 1.9432878]|\n",
      "|     31|[25, 1.7884777]|\n",
      "|     85| [8, 4.5071225]|\n",
      "|     85| [9, 3.7352915]|\n",
      "|     85|[14, 3.6781254]|\n",
      "|     85|[17, 3.5990434]|\n",
      "|     85|[21, 2.9416435]|\n",
      "|     85| [6, 2.9200158]|\n",
      "|     85| [1, 1.8101648]|\n",
      "|     85|[18, 1.5493659]|\n",
      "|     85| [4, 1.5392141]|\n",
      "|     85|[12, 1.1931009]|\n",
      "+-------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alsModel.recommendForAllUsers(10)\\\n",
    "  .selectExpr(\"userId\", \"explode(recommendations)\").show()\n",
    "alsModel.recommendForAllItems(10)\\\n",
    "  .selectExpr(\"movieId\", \"explode(recommendations)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.863871\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator()\\\n",
    "  .setMetricName(\"rmse\")\\\n",
    "  .setLabelCol(\"rating\")\\\n",
    "  .setPredictionCol(\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print((\"Root-mean-square error = %f\" % rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "regComparison = predictions.select(\"rating\", \"prediction\")\\\n",
    "  .rdd.map(lambda x: (x(0), x(1)))\n",
    "metrics = RegressionMetrics(regComparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RankingMetrics, RegressionMetrics\n",
    "from pyspark.sql.functions import col, expr\n",
    "perUserActual = predictions\\\n",
    "  .where(\"rating > 2.5\")\\\n",
    "  .groupBy(\"userId\")\\\n",
    "  .agg(expr(\"collect_set(movieId) as movies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perUserPredictions = predictions\\\n",
    "  .orderBy(col(\"userId\"), expr(\"prediction DESC\"))\\\n",
    "  .groupBy(\"userId\")\\\n",
    "  .agg(expr(\"collect_list(movieId) as movies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "perUserActualvPred = perUserActual.join(perUserPredictions, [\"userId\"]).rdd\\\n",
    "  .map(lambda row: (row[1], row[2][:15]))\n",
    "ranks = RankingMetrics(perUserActualvPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5076923076923078"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks.meanAveragePrecision\n",
    "ranks.precisionAt(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
